Simple implementations of Bandit Algorithms, specifically for Bernoulli Bandits. Implementations are based on pseudocode given from the textbooks 'A Tutorial on Thompson Sampling'(https://arxiv.org/abs/1707.02038) and 'Bandit Algorithms' (1.Lattimore T, Szepesv√°ri C. Stochastic Bandits with 
Finitely Many Arms. In: Bandit Algorithms. Cambridge University Press; 2020:73-74.)
An implementation of multiple different methods for solving the Multi-Armed Bandit, specifically the Bernoulli case. The implementation involves methods such as Explore-Then-Commit, Greedy, Thompson Sampling, UCB, MOSS, AdaUCB, KL-UCB. \
Uncomment and alter the line at the bottom to specify the experiment(s) desired
